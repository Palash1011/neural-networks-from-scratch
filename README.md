# Neural Networks From Scratch

This project implements a fully connected deep neural network from scratch using NumPy.
No deep learning frameworks (TensorFlow, PyTorch, Keras) are used for training.

## Features
- Forward and backward propagation
- ReLU activation and Softmax output
- Categorical cross-entropy loss
- Adam optimizer
- Mini-batch training
- L2 regularization

## Dataset
The network was trained and evaluated on the MNIST handwritten digit dataset.

## Results
The model achieves approximately **98% test accuracy** on MNIST.

## Files
- `Neural_Networks_From_Scratch.ipynb` â€“ Training, evaluation, and plots
